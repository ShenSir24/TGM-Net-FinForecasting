{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ed63275",
   "metadata": {},
   "source": [
    "# 实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc32fbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filtered feature data has been successfully loaded from experiment_data_refined.pkl.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 直读取最优特征数据集\n",
    "with open('../data/processed/experiment_data_refined.pkl', 'rb') as f:\n",
    "    experiment_data_refined = pickle.load(f)\n",
    "\n",
    "print(\"The filtered feature data has been successfully loaded from experiment_data_refined.pkl.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba3f10",
   "metadata": {},
   "source": [
    "## 模型实验（Baseline）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410d01f",
   "metadata": {},
   "source": [
    "### ARIMAX（带有外生变量的 ARIMA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01a35ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                    Window = 5                   Window = 21                   Window = 63          \n",
      "                  RMSE     MAE      R2  DA (%)     RMSE     MAE      R2  DA (%)     RMSE     MAE      R2  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "ARIMAX          0.0113  0.0082 -0.0598   50.64   0.0117  0.0087 -0.1263   50.55   0.0130  0.0101 -0.4006   47.25  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"ARIMAX\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 数据展平处理 (N, L, D) -> (N, L*D) 适配传统计量模型\n",
    "    N_tr, L, D = data['X_train'].shape\n",
    "    X_train_flat = data['X_train'].reshape(N_tr, L * D)\n",
    "    N_te = data['X_test'].shape[0]\n",
    "    X_test_flat = data['X_test'].reshape(N_te, L * D)\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    model = sm.tsa.ARIMA(endog=y_train, exog=X_train_flat, order=(1, 0, 0))\n",
    "    res = model.fit()\n",
    "    \n",
    "    # 3. 模型预测 (修正了.values的问题，直接转np.array并展平)\n",
    "    y_pred = np.array(res.forecast(steps=len(y_true), exog=X_test_flat)).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<15}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<15}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<15}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69103434",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e644aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                    Window = 5                   Window = 21                   Window = 63          \n",
      "                  RMSE     MAE      R2  DA (%)     RMSE     MAE      R2  DA (%)     RMSE     MAE      R2  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "XGBoost         0.0123  0.0092 -0.2751   50.43   0.0123  0.0094 -0.2599   50.76   0.0123  0.0092 -0.2376   52.75  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"XGBoost\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 数据展平处理 (N, L, D) -> (N, L*D) 适配机器学习模型\n",
    "    N_tr, L, D = data['X_train'].shape\n",
    "    X_train_flat = data['X_train'].reshape(N_tr, L * D)\n",
    "    N_te = data['X_test'].shape[0]\n",
    "    X_test_flat = data['X_test'].reshape(N_te, L * D)\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    model = xgb.XGBRegressor(n_estimators=100, max_depth=6, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train_flat, y_train)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_flat).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<15}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<15}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<15}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e7c59",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a41d17b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                    Window = 5                   Window = 21                   Window = 63          \n",
      "                  RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "LSTM            0.0155  0.0108 -1.0170   51.07   0.0163  0.0112 -1.2084   50.44   0.0223  0.0159 -3.0779   48.28  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"LSTM\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)，深度学习天然支持该形状，无需展平\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    model = Sequential([\n",
    "        LSTM(32, input_shape=(L, D)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # 为了演示极简且可运行，设置epochs=50。设置shuffle=False保留时序特征\n",
    "    model.fit(X_train_3d, y_train, epochs=50, batch_size=32, verbose=0, shuffle=False)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<15}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<15}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<15}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a48cf4",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba2b9843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                    Window = 5                   Window = 21                   Window = 63          \n",
      "                  RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "GRU             0.0170  0.0112 -1.4292   49.25   0.0296  0.0174 -6.2515   46.62   0.0199  0.0121 -2.2636   54.12  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"GRU\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    model = Sequential([\n",
    "        GRU(32, input_shape=(L, D)),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # 保持与LSTM一致的训练参数配置\n",
    "    model.fit(X_train_3d, y_train, epochs=50, batch_size=32, verbose=0, shuffle=False)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<15}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<15}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<15}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59622899",
   "metadata": {},
   "source": [
    "### 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48fe1475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                    Window = 5                   Window = 21                   Window = 63          \n",
      "                  RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "1D-CNN          0.0190  0.0146 -2.0158   50.00   0.0205  0.0161 -2.4732   48.80   0.0410  0.0315 -12.8136   48.05  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"1D-CNN\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D) 适配 1D-CNN\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    # 根据窗口大小动态调整 kernel_size，防止 kernel_size 大于窗口长度\n",
    "    k_size = 3 if L >= 3 else L \n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=k_size, activation='relu', input_shape=(L, D)),\n",
    "        Flatten(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    model.fit(X_train_3d, y_train, epochs=50, batch_size=32, verbose=0, shuffle=False)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<15}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<15}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<15}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d4d62",
   "metadata": {},
   "source": [
    "### PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2480aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                    Window = 5                   Window = 21                   Window = 63          \n",
      "                  RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "PatchTST        0.0309  0.0234 -6.9975   50.75   0.0279  0.0185 -5.4267   45.96   0.0458  0.0312 -16.2883   50.34  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, Embedding, MultiHeadAttention, LayerNormalization, Dense, Flatten\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"PatchTST\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合 (使用 Functional API 极简实现 PatchTST 核心逻辑)\n",
    "    # 动态设定 Patch 长度，确保不同窗口 L 下都能有效分块\n",
    "    patch_len = max(2, L // 5) \n",
    "    \n",
    "    inputs = Input(shape=(L, D))\n",
    "    # Patching 阶段：利用 stride Conv1D 实现无重叠切块与线性映射\n",
    "    x = Conv1D(filters=32, kernel_size=patch_len, strides=patch_len, padding='valid')(inputs)\n",
    "    \n",
    "    # Positional Encoding 阶段\n",
    "    num_patches = x.shape[1]\n",
    "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "    pos_emb = Embedding(input_dim=num_patches, output_dim=32)(positions)\n",
    "    x = x + pos_emb\n",
    "    \n",
    "    # Transformer Encoder 阶段 (单层极简版)\n",
    "    attn_out = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = LayerNormalization()(x + attn_out)\n",
    "    ffn_out = Dense(32, activation='relu')(x)\n",
    "    x = LayerNormalization()(x + ffn_out)\n",
    "    \n",
    "    # 预测头\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    model.fit(X_train_3d, y_train, epochs=50, batch_size=32, verbose=0, shuffle=False)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<15}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<15}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<15}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f3bc4",
   "metadata": {},
   "source": [
    "### iTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57dc40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                    Window = 5                   Window = 21                   Window = 63          \n",
      "                  RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "iTransformer    0.0378  0.0290 -10.9864   48.28   0.0432  0.0343 -14.4362   48.91   0.0281  0.0219 -5.5111   53.32  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, MultiHeadAttention, LayerNormalization, Permute\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"iTransformer\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合 (使用 Functional API 实现 iTransformer 核心逻辑)\n",
    "    inputs = Input(shape=(L, D))\n",
    "    \n",
    "    # 修正：使用 Keras 原生 Permute 层代替 tf.transpose 避免 KerasTensor 类型报错\n",
    "    # 参数 (2, 1) 表示转置输入的第2维度(D)和第1维度(L)，Batch维度0由Keras自动处理隐藏\n",
    "    x = Permute((2, 1))(inputs)\n",
    "    \n",
    "    # 线性映射投影到 d_model 维度\n",
    "    x = Dense(32)(x)\n",
    "    \n",
    "    # Transformer Encoder 阶段 (处理各个变量 Token 之间的交互)\n",
    "    attn_out = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = LayerNormalization()(x + attn_out)\n",
    "    ffn_out = Dense(32, activation='relu')(x)\n",
    "    x = LayerNormalization()(x + ffn_out)\n",
    "    \n",
    "    # 预测头\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    model.fit(X_train_3d, y_train, epochs=50, batch_size=32, verbose=0, shuffle=False)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<15}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<15}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<15}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a7837",
   "metadata": {},
   "source": [
    "### TimesNet-GRU-MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e5d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Flatten, Dense\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# tf.get_logger().setLevel('ERROR')\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# # 初始化全局存储结构\n",
    "# if 'all_results' not in globals():\n",
    "#     all_results = []\n",
    "# if 'all_errors' not in globals():\n",
    "#     all_errors = []\n",
    "\n",
    "# model_name = \"TimesNet-GRU-MHA\"\n",
    "# current_results = {}\n",
    "\n",
    "# # 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "# all_results = [res for res in all_results if res['model'] != model_name]\n",
    "# all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "# for w, data in experiment_data_refined.items():\n",
    "#     # 1. 提取3D特征张量 (N, L, D)\n",
    "#     X_train_3d = data['X_train']\n",
    "#     X_test_3d = data['X_test']\n",
    "    \n",
    "#     y_train = data['y_train'].flatten()\n",
    "#     y_true = data['y_test'].flatten()\n",
    "    \n",
    "#     N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "#     # 2. 模型构建与拟合 (使用 Functional API 实现级联混合架构)\n",
    "#     inputs = Input(shape=(L, D))\n",
    "    \n",
    "#     # 模块 A: 极简版 TimesNet 核心思想近似 (使用1D卷积捕捉局部多周期时序特征)\n",
    "#     k_size = 3 if L >= 3 else L \n",
    "#     x = Conv1D(filters=32, kernel_size=k_size, padding='same', activation='relu')(inputs)\n",
    "    \n",
    "#     # 模块 B: GRU 层 (提取序列全局长短期依赖，保留时间步维度)\n",
    "#     x = GRU(32, return_sequences=True)(x)\n",
    "    \n",
    "#     # 模块 C: MHA 层 (多头注意力机制进行特征加权与跨时间步交互)\n",
    "#     attn_out = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "#     x = LayerNormalization()(x + attn_out)\n",
    "    \n",
    "#     # 预测头\n",
    "#     x = Flatten()(x)\n",
    "#     outputs = Dense(1)(x)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "#     model.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "#     model.fit(X_train_3d, y_train, epochs=50, batch_size=32, verbose=0, shuffle=False)\n",
    "    \n",
    "#     # 3. 模型预测\n",
    "#     y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "#     # 4. 基准预测 (零收益)\n",
    "#     y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "#     # 5. 指标计算\n",
    "#     rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "#     mae = np.mean(np.abs(y_true - y_pred))\n",
    "#     r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "#     da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "#     # 6. 误差序列计算\n",
    "#     e_t = y_true - y_pred\n",
    "#     e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "#     # 7. 组装结果字典\n",
    "#     results_dict = {\n",
    "#         \"model\": model_name,\n",
    "#         \"window\": w,\n",
    "#         \"RMSE\": rmse,\n",
    "#         \"MAE\": mae,\n",
    "#         \"R2_OS\": r2_os,\n",
    "#         \"DA\": da\n",
    "#     }\n",
    "    \n",
    "#     error_dict = {\n",
    "#         \"model\": model_name,\n",
    "#         \"window\": w,\n",
    "#         \"errors\": e_t,\n",
    "#         \"benchmark_errors\": e0_t\n",
    "#     }\n",
    "    \n",
    "#     # 8. 存储结果\n",
    "#     all_results.append(results_dict)\n",
    "#     all_errors.append(error_dict)\n",
    "#     current_results[w] = results_dict\n",
    "\n",
    "# # ---------------- 输出格式模拟 ----------------\n",
    "# print(\"-\" * 110)\n",
    "# # 表头第一行：窗口\n",
    "# header_win = f\"{'Model':<20}\"\n",
    "# # 表头第二行：指标\n",
    "# header_met = f\"{'':<20}\"\n",
    "# # 数据行\n",
    "# row_data = f\"{model_name:<20}\"\n",
    "\n",
    "# for w in experiment_data_refined.keys():\n",
    "#     header_win += f\"{f'Window = {w}':^30}\"\n",
    "#     header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "#     res = current_results[w]\n",
    "#     row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "# print(header_win)\n",
    "# print(header_met)\n",
    "# print(\"-\" * 110)\n",
    "# print(row_data)\n",
    "# print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b50174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Dense, Concatenate, Dropout, SpatialDropout1D, GlobalAveragePooling1D\n",
    "# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras import regularizers\n",
    "# import warnings\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "# tf.get_logger().setLevel('ERROR')\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# # 初始化全局存储结构\n",
    "# if 'all_results' not in globals():\n",
    "#     all_results = []\n",
    "# if 'all_errors' not in globals():\n",
    "#     all_errors = []\n",
    "\n",
    "# model_name = \"TimesNet-GRU-MHA\"\n",
    "# current_results = {}\n",
    "\n",
    "# # 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "# all_results = [res for res in all_results if res['model'] != model_name]\n",
    "# all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "# for w, data in experiment_data_refined.items():\n",
    "#     # 1. 提取3D特征张量 (N, L, D)\n",
    "#     X_train_3d = data['X_train']\n",
    "#     X_test_3d = data['X_test']\n",
    "    \n",
    "#     y_train = data['y_train'].flatten()\n",
    "#     y_true = data['y_test'].flatten()\n",
    "    \n",
    "#     N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "#     # 2. 模型构建与拟合 (优化版架构)\n",
    "#     inputs = Input(shape=(L, D))\n",
    "    \n",
    "#     # 模块 A: 多尺度 1D 卷积 (捕获不同频带局部特征)，加入 L2 正则防过拟合\n",
    "#     k_sizes = list(set([min(k, L) for k in [2, 3, 5]]))\n",
    "#     convs = [Conv1D(filters=16, kernel_size=k, padding='same', activation='relu', \n",
    "#                     kernel_regularizer=regularizers.l2(1e-4))(inputs) for k in k_sizes]\n",
    "#     x = Concatenate()(convs) if len(convs) > 1 else convs[0]\n",
    "#     x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "#     # 模块 B: GRU 层 (降低隐藏单元数防过拟合，保留时间步)\n",
    "#     x_gru = GRU(32, return_sequences=True)(x)\n",
    "#     x_gru = Dropout(0.2)(x_gru)\n",
    "    \n",
    "#     # 模块 C: MHA 层 (优化注意力头数与维度，引入残差与层归一化)\n",
    "#     attn_out = MultiHeadAttention(num_heads=2, key_dim=16, dropout=0.2)(x_gru, x_gru)\n",
    "#     x = LayerNormalization()(x_gru + attn_out)\n",
    "    \n",
    "#     # 预测头 (使用全局平均池化替代 Flatten 减少参数量，降低过拟合风险)\n",
    "#     x = GlobalAveragePooling1D()(x)\n",
    "#     outputs = Dense(1, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "#     # 模块 D: 训练策略优化 (动态学习率 + 提前停止)\n",
    "#     optimizer = Adam(learning_rate=0.001)\n",
    "#     model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "#     callbacks = [\n",
    "#         EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "#         ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "#     ]\n",
    "    \n",
    "#     # 使用 validation_split=0.1 监控过拟合，提高 epochs 让 ES 自动截断\n",
    "#     model.fit(X_train_3d, y_train, epochs=150, batch_size=32, \n",
    "#               validation_split=0.1, verbose=0, shuffle=False, callbacks=callbacks)\n",
    "    \n",
    "#     # 3. 模型预测\n",
    "#     y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "#     # 4. 基准预测 (零收益)\n",
    "#     y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "#     # 5. 指标计算\n",
    "#     rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "#     mae = np.mean(np.abs(y_true - y_pred))\n",
    "#     r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "#     da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "#     # 6. 误差序列计算\n",
    "#     e_t = y_true - y_pred\n",
    "#     e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "#     # 7. 组装结果字典\n",
    "#     results_dict = {\n",
    "#         \"model\": model_name,\n",
    "#         \"window\": w,\n",
    "#         \"RMSE\": rmse,\n",
    "#         \"MAE\": mae,\n",
    "#         \"R2_OS\": r2_os,\n",
    "#         \"DA\": da\n",
    "#     }\n",
    "    \n",
    "#     error_dict = {\n",
    "#         \"model\": model_name,\n",
    "#         \"window\": w,\n",
    "#         \"errors\": e_t,\n",
    "#         \"benchmark_errors\": e0_t\n",
    "#     }\n",
    "    \n",
    "#     # 8. 存储结果\n",
    "#     all_results.append(results_dict)\n",
    "#     all_errors.append(error_dict)\n",
    "#     current_results[w] = results_dict\n",
    "\n",
    "# # ---------------- 输出格式模拟 ----------------\n",
    "# print(\"-\" * 110)\n",
    "# # 表头第一行：窗口\n",
    "# header_win = f\"{'Model':<20}\"\n",
    "# # 表头第二行：指标\n",
    "# header_met = f\"{'':<20}\"\n",
    "# # 数据行\n",
    "# row_data = f\"{model_name:<20}\"\n",
    "\n",
    "# for w in experiment_data_refined.keys():\n",
    "#     header_win += f\"{f'Window = {w}':^30}\"\n",
    "#     header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "#     res = current_results[w]\n",
    "#     row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "# print(header_win)\n",
    "# print(header_met)\n",
    "# print(\"-\" * 110)\n",
    "# print(row_data)\n",
    "# print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420f978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                         Window = 5                   Window = 21                   Window = 63          \n",
      "                       RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TimesNet-GRU-MHA     0.0110  0.0080 -0.0097   48.71   0.0110  0.0080 -0.0024   50.33   0.0110  0.0081 -0.0014   51.49  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Dense, Concatenate, Dropout, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "model_name = \"TimesNet-GRU-MHA\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合 (优化版架构)\n",
    "    inputs = Input(shape=(L, D))\n",
    "    \n",
    "    # 模块 A: 多尺度 1D 卷积 (捕获不同频带局部特征)，加入 L2 正则防过拟合\n",
    "    k_sizes = list(set([min(k, L) for k in [2, 3, 5]]))\n",
    "    convs = [Conv1D(filters=16, kernel_size=k, padding='same', activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(1e-4))(inputs) for k in k_sizes]\n",
    "    x = Concatenate()(convs) if len(convs) > 1 else convs[0]\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "    # 模块 B: GRU 层 (降低隐藏单元数防过拟合，保留时间步)\n",
    "    x_gru = GRU(24, return_sequences=True)(x)\n",
    "    x_gru = Dropout(0.2)(x_gru)\n",
    "    \n",
    "    # 模块 C: MHA 层 (优化注意力头数与维度，引入残差与层归一化)\n",
    "    attn_out = MultiHeadAttention(num_heads=5, key_dim=16, dropout=0.2)(x_gru, x_gru)\n",
    "    x = LayerNormalization()(x_gru + attn_out)\n",
    "    \n",
    "    # 预测头 (使用全局平均池化替代 Flatten 减少参数量，降低过拟合风险)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(1, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 模块 D: 训练策略优化 (动态学习率 + 提前停止)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "    ]\n",
    "    \n",
    "    # 使用 validation_split=0.1 监控过拟合，提高 epochs 让 ES 自动截断\n",
    "    model.fit(X_train_3d, y_train, epochs=150, batch_size=32, \n",
    "              validation_split=0.1, verbose=0, shuffle=False, callbacks=callbacks)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<20}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<20}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<20}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96910a89",
   "metadata": {},
   "source": [
    "### 基准DM检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5acc732d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. 定义 Diebold-Mariano 检验函数\n",
    "def dm_test(e1, e2, h=1):\n",
    "    \"\"\"\n",
    "    e1: 目标模型误差 (TimesNet-GRU-MHA)\n",
    "    e2: 基准模型误差 (Baseline)\n",
    "    h: 预测步长 (默认为 1)\n",
    "    \"\"\"\n",
    "    # ====== [安全机制：强制尾部对齐] ======\n",
    "    min_len = min(len(e1), len(e2))\n",
    "    e1 = np.array(e1)[-min_len:]\n",
    "    e2 = np.array(e2)[-min_len:]\n",
    "    # ======================================\n",
    "    \n",
    "    d = e2**2 - e1**2 \n",
    "    T = len(d)\n",
    "    d_mean = np.mean(d)\n",
    "    \n",
    "    # 计算自动协方差 (Newey-West)\n",
    "    gamma = np.zeros(h)\n",
    "    for i in range(h):\n",
    "        gamma[i] = np.sum((d[i:] - d_mean) * (d[:T-i] - d_mean)) / T\n",
    "        \n",
    "    var_d = gamma[0]\n",
    "    for i in range(1, h):\n",
    "        var_d += 2.0 * gamma[i]\n",
    "        \n",
    "    if var_d <= 0:\n",
    "        return np.nan, np.nan\n",
    "        \n",
    "    DM_stat = d_mean / np.sqrt(var_d / T)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(DM_stat)))\n",
    "    \n",
    "    return DM_stat, p_value\n",
    "\n",
    "# ====== [修复点：增加 stat 参数，严格限制只奖励正向效果] ======\n",
    "def get_significance_stars(p, stat):\n",
    "    if np.isnan(p) or stat <= 0: return \"\"\n",
    "    if p < 0.01: return \"***\"\n",
    "    if p < 0.05: return \"**\"\n",
    "    if p < 0.10: return \"*\"\n",
    "    return \"\"\n",
    "# ==============================================================\n",
    "\n",
    "# 2. 提取需要检验的模型名称与动态获取窗口列表\n",
    "target_model = \"TimesNet-GRU-MHA\"\n",
    "baselines = [\"ARIMAX\", \"XGBoost\", \"LSTM\", \"GRU\", \"1D-CNN\", \"PatchTST\", \"iTransformer\"]\n",
    "\n",
    "# 从全局字典中动态获取所有存在的窗口\n",
    "windows = sorted(list(set([err['window'] for err in all_errors])))\n",
    "\n",
    "dm_results = {b: {} for b in baselines}\n",
    "\n",
    "# 3. 遍历计算目标模型与各个基准模型在不同窗口下的 DM 统计量\n",
    "for w in windows:\n",
    "    # 获取目标模型在当前窗口的最新误差序列\n",
    "    e_target_list = [err['errors'] for err in all_errors if err['model'] == target_model and err['window'] == w]\n",
    "    if not e_target_list:\n",
    "        print(f\"警告: 未找到目标模型 {target_model} 在 Window={w} 的误差序列。\")\n",
    "        continue\n",
    "    e_target = e_target_list[-1] \n",
    "    \n",
    "    for b in baselines:\n",
    "        e_base_list = [err['errors'] for err in all_errors if err['model'] == b and err['window'] == w]\n",
    "        if not e_base_list:\n",
    "            dm_results[b][w] = (np.nan, np.nan)\n",
    "            continue\n",
    "        e_base = e_base_list[-1]\n",
    "        \n",
    "        # 计算 DM 统计量与 p 值\n",
    "        stat, p = dm_test(e_target, e_base, h=1)\n",
    "        dm_results[b][w] = (stat, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab924b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Baseline Model                 Window = 5                     Window = 21                     Window = 63           \n",
      "                       DM-Stat    p-value      Sig     DM-Stat    p-value      Sig     DM-Stat    p-value      Sig  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "ARIMAX                3.007523   0.002634      ***    4.718623   0.000002      ***    8.366116   0.000000      ***  \n",
      "XGBoost               6.180784   0.000000      ***    6.923504   0.000000      ***    6.559726   0.000000      ***  \n",
      "LSTM                  3.448898   0.000563      ***    5.440346   0.000000      ***    6.982010   0.000000      ***  \n",
      "GRU                   2.873298   0.004062      ***    2.654235   0.007949      ***    2.802451   0.005072      ***  \n",
      "1D-CNN               12.609740   0.000000      ***   14.089593   0.000000      ***   16.544753   0.000000      ***  \n",
      "PatchTST             12.112632   0.000000      ***    8.148978   0.000000      ***   10.421540   0.000000      ***  \n",
      "iTransformer         13.153032   0.000000      ***   19.705662   0.000000      ***   15.460898   0.000000      ***  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Note: Target Model = TimesNet-GRU-MHA.\n",
      "Positive DM-Stat indicates the Target Model outperforms the Baseline Model (MSE loss).\n",
      "Significance levels: *** p<0.01, ** p<0.05, * p<0.1 (Only when Target > Baseline).\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 4. 输出格式 (Diebold-Mariano Test Results) ----------------\n",
    "print(\"-\" * 120)\n",
    "header_win = f\"{'Baseline Model':<20}\"\n",
    "header_met = f\"{'':<20}\"\n",
    "\n",
    "for w in windows:\n",
    "    header_win += f\"{f'Window = {w}':^32}\"\n",
    "    header_met += f\"{'DM-Stat':>10} {'p-value':>10} {'Sig':>8}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for b in baselines:\n",
    "    row = f\"{b:<20}\"\n",
    "    for w in windows:\n",
    "        if w in dm_results[b] and not np.isnan(dm_results[b][w][0]):\n",
    "            stat, p = dm_results[b][w]\n",
    "            # 这里传入 stat 配合我们修复的函数\n",
    "            stars = get_significance_stars(p, stat)\n",
    "            row += f\"{stat:>10.6f} {p:>10.6f} {stars:>8}  \"\n",
    "        else:\n",
    "            row += f\"{'-':>10} {'-':>10} {'':>8}  \"\n",
    "    print(row)\n",
    "print(\"-\" * 120)\n",
    "print(f\"Note: Target Model = {target_model}.\")\n",
    "print(\"Positive DM-Stat indicates the Target Model outperforms the Baseline Model (MSE loss).\")\n",
    "print(\"Significance levels: *** p<0.01, ** p<0.05, * p<0.1 (Only when Target > Baseline).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f542ba17",
   "metadata": {},
   "source": [
    "基准模型 (Baselines) 导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "72304ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DM results of Baselines have been saved to: ../results/tables/dm_results_baselines.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 提取并扁平化嵌套字典数据\n",
    "rows = []\n",
    "for model_name, window_data in dm_results.items():\n",
    "    for w, (stat, p) in window_data.items():\n",
    "        stars = get_significance_stars(p, stat) if not np.isnan(stat) else \"\"\n",
    "        rows.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Window\": w,\n",
    "            \"DM_Stat\": stat,\n",
    "            \"P_Value\": p,\n",
    "            \"Significance\": stars\n",
    "        })\n",
    "\n",
    "df_dm = pd.DataFrame(rows)\n",
    "\n",
    "# 直接建目录并保存 CSV\n",
    "os.makedirs('../results/tables', exist_ok=True)\n",
    "save_path = '../results/tables/dm_results_baselines.csv'\n",
    "df_dm.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"The DM results of Baselines have been saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c411f07",
   "metadata": {},
   "source": [
    "## 消融实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65eec3",
   "metadata": {},
   "source": [
    "### w/o FFT Extraction（移除动态周期发现）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75cd6f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                         Window = 5                   Window = 21                   Window = 63          \n",
      "                       RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TimesNet-GRU-MHA (w/o FFT) 0.0116  0.0085 -0.1283   47.64   0.0176  0.0116 -1.5573   47.93   0.0324  0.0268 -7.6433   49.43  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 消融实验版本：TimesNet-GRU-MHA (w/o FFT Extraction)\n",
    "# 移除多尺度自适应提取，强制使用固定周期 (金融常见 p=5 天) 将一维折叠为二维进行特征提取\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Dense, Concatenate, Dropout, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "# 消融版本名称\n",
    "model_name = \"TimesNet-GRU-MHA (w/o FFT)\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    inputs = Input(shape=(L, D))\n",
    "    \n",
    "    # 【消融点】：移除模块 A (多尺度 1D 卷积/动态周期发现)，直接将特征送入模块 B\n",
    "    \n",
    "    # 模块 B: GRU 层 (降低隐藏单元数防过拟合，保留时间步)\n",
    "    x_gru = GRU(24, return_sequences=True)(inputs)\n",
    "    x_gru = Dropout(0.2)(x_gru)\n",
    "    \n",
    "    # 模块 C: MHA 层 (优化注意力头数与维度，引入残差与层归一化)\n",
    "    attn_out = MultiHeadAttention(num_heads=5, key_dim=16, dropout=0.2)(x_gru, x_gru)\n",
    "    x = LayerNormalization()(x_gru + attn_out)\n",
    "    \n",
    "    # 预测头 (使用全局平均池化替代 Flatten 减少参数量，降低过拟合风险)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(1, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 模块 D: 训练策略优化 (动态学习率 + 提前停止)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "    ]\n",
    "    \n",
    "    # 使用 validation_split=0.1 监控过拟合，提高 epochs 让 ES 自动截断\n",
    "    model.fit(X_train_3d, y_train, epochs=150, batch_size=32, \n",
    "              validation_split=0.1, verbose=0, shuffle=False, callbacks=callbacks)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<20}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<20}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<20}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a03a5",
   "metadata": {},
   "source": [
    "### w/o 2D Inception（退化为 1D 基线）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "74cb851c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                         Window = 5                   Window = 21                   Window = 63          \n",
      "                       RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TimesNet-GRU-MHA (w/o 2D Inception) 0.0114  0.0084 -0.0939   45.39   0.0111  0.0081 -0.0199   48.03   0.0115  0.0086 -0.0874   47.94  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 消融实验版本：TimesNet-GRU-MHA (w/o 2D Inception)\n",
    "# 移除 1D 到 2D 重塑及多尺度 Inception 结构，退化为标准的单尺度 1D 卷积表示\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Dense, Concatenate, Dropout, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "# 消融版本名称\n",
    "model_name = \"TimesNet-GRU-MHA (w/o 2D Inception)\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    inputs = Input(shape=(L, D))\n",
    "    \n",
    "    # 【消融点】：退化为标准的单尺度 1D 卷积表示 (移除多尺度/Inception特性)\n",
    "    x = Conv1D(filters=16, kernel_size=3, padding='same', activation='relu', \n",
    "               kernel_regularizer=regularizers.l2(1e-4))(inputs)\n",
    "    x = SpatialDropout1D(0.1)(x)\n",
    "    \n",
    "    # 模块 B: GRU 层 (降低隐藏单元数防过拟合，保留时间步)\n",
    "    x_gru = GRU(24, return_sequences=True)(x)\n",
    "    x_gru = Dropout(0.1)(x_gru)\n",
    "    \n",
    "    # 模块 C: MHA 层 (优化注意力头数与维度，引入残差与层归一化)\n",
    "    attn_out = MultiHeadAttention(num_heads=5, key_dim=16, dropout=0.1)(x_gru, x_gru)\n",
    "    x = LayerNormalization()(x_gru + attn_out)\n",
    "    \n",
    "    # 预测头 (使用全局平均池化替代 Flatten 减少参数量，降低过拟合风险)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(1, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 模块 D: 训练策略优化 (动态学习率 + 提前停止)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "    ]\n",
    "    \n",
    "    # 使用 validation_split=0.1 监控过拟合，提高 epochs 让 ES 自动截断\n",
    "    model.fit(X_train_3d, y_train, epochs=150, batch_size=32, \n",
    "              validation_split=0.1, verbose=0, shuffle=False, callbacks=callbacks)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<20}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<20}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<20}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e7dc7a",
   "metadata": {},
   "source": [
    "### w/o GRU（移除循环非线性演化模块）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5053783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                         Window = 5                   Window = 21                   Window = 63          \n",
      "                       RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TimesNet-MHA (w/o GRU) 0.0111  0.0081 -0.0259   49.14   0.0232  0.0187 -3.4532   48.47   0.0136  0.0107 -0.5168   46.11  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 消融实验版本：w/o GRU (即 TimesNet-MHA，移除 GRU 层)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Dense, Concatenate, Dropout, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "# 消融版本名称\n",
    "model_name = \"TimesNet-MHA (w/o GRU)\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    inputs = Input(shape=(L, D))\n",
    "    \n",
    "    # 模块 A: 多尺度 1D 卷积 (捕获不同频带局部特征)，加入 L2 正则防过拟合\n",
    "    k_sizes = list(set([min(k, L) for k in [2, 3, 5]]))\n",
    "    convs = [Conv1D(filters=16, kernel_size=k, padding='same', activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(1e-4))(inputs) for k in k_sizes]\n",
    "    x = Concatenate()(convs) if len(convs) > 1 else convs[0]\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    \n",
    "    # 【消融点】：移除模块 B (GRU 层)，特征直接送入 MHA 层\n",
    "    \n",
    "    # 模块 C: MHA 层 (优化注意力头数与维度，引入残差与层归一化)\n",
    "    attn_out = MultiHeadAttention(num_heads=5, key_dim=16, dropout=0.2)(x, x)\n",
    "    x = LayerNormalization()(x + attn_out)\n",
    "    \n",
    "    # 预测头 (使用全局平均池化替代 Flatten 减少参数量，降低过拟合风险)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(1, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 模块 D: 训练策略优化 (动态学习率 + 提前停止)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "    ]\n",
    "    \n",
    "    # 使用 validation_split=0.1 监控过拟合，提高 epochs 让 ES 自动截断\n",
    "    model.fit(X_train_3d, y_train, epochs=150, batch_size=32, \n",
    "              validation_split=0.1, verbose=0, shuffle=False, callbacks=callbacks)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<20}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<20}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<20}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3a03e",
   "metadata": {},
   "source": [
    "### w/o MHA（移除多头注意力机制）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e60da38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                         Window = 5                   Window = 21                   Window = 63          \n",
      "                       RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "TimesNet-GRU (w/o MHA) 0.0114  0.0084 -0.0836   48.50   0.0111  0.0082 -0.0276   47.49   0.0113  0.0084 -0.0443   48.05  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 消融实验版本：w/o MHA (即 TimesNet-GRU，移除多头注意力机制)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Dense, Concatenate, Dropout, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "# 消融版本名称\n",
    "model_name = \"TimesNet-GRU (w/o MHA)\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    inputs = Input(shape=(L, D))\n",
    "    \n",
    "    # 模块 A: 多尺度 1D 卷积 (捕获不同频带局部特征)，加入 L2 正则防过拟合\n",
    "    k_sizes = list(set([min(k, L) for k in [2, 3, 5]]))\n",
    "    convs = [Conv1D(filters=16, kernel_size=k, padding='same', activation='relu', \n",
    "                    kernel_regularizer=regularizers.l2(1e-4))(inputs) for k in k_sizes]\n",
    "    x = Concatenate()(convs) if len(convs) > 1 else convs[0]\n",
    "    x = SpatialDropout1D(0.001)(x)\n",
    "    \n",
    "    # 模块 B: GRU 层 (降低隐藏单元数防过拟合，保留时间步)\n",
    "    x_gru = GRU(32, return_sequences=True)(x)\n",
    "    x_gru = Dropout(0.001)(x_gru)\n",
    "    \n",
    "    # 【消融点】：移除模块 C (MHA 层与层归一化残差连接)，GRU 输出直接进入预测头\n",
    "    \n",
    "    # 预测头 (使用全局平均池化替代 Flatten 减少参数量，降低过拟合风险)\n",
    "    x = GlobalAveragePooling1D()(x_gru)\n",
    "    outputs = Dense(1, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 模块 D: 训练策略优化 (动态学习率 + 提前停止)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "    ]\n",
    "    \n",
    "    # 使用 validation_split=0.1 监控过拟合，提高 epochs 让 ES 自动截断\n",
    "    model.fit(X_train_3d, y_train, epochs=150, batch_size=32, \n",
    "              validation_split=0.1, verbose=0, shuffle=False, callbacks=callbacks)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<20}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<20}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<20}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f51e87",
   "metadata": {},
   "source": [
    "### w/o TimesNet (即普通的 GRU-MHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96386d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------\n",
      "Model                         Window = 5                   Window = 21                   Window = 63          \n",
      "                       RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)     RMSE     MAE   R2_OS  DA (%)  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "GRU-MHA (w/o TimesNet) 0.0120  0.0088 -0.2115   48.82   0.0135  0.0100 -0.5125   48.91   0.0232  0.0181 -3.4307   48.05  \n",
      "--------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 消融实验版本：w/o TimesNet (即普通的 GRU-MHA，移除多尺度1D卷积模块)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GRU, MultiHeadAttention, LayerNormalization, Dense, Concatenate, Dropout, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 初始化全局存储结构\n",
    "if 'all_results' not in globals():\n",
    "    all_results = []\n",
    "if 'all_errors' not in globals():\n",
    "    all_errors = []\n",
    "\n",
    "# 消融版本名称\n",
    "model_name = \"GRU-MHA (w/o TimesNet)\"\n",
    "current_results = {}\n",
    "\n",
    "# 清理逻辑：覆盖当前模型的历史运行记录，防止重复 append 污染最终的 DM 检验\n",
    "all_results = [res for res in all_results if res['model'] != model_name]\n",
    "all_errors = [err for err in all_errors if err['model'] != model_name]\n",
    "\n",
    "for w, data in experiment_data_refined.items():\n",
    "    # 1. 提取3D特征张量 (N, L, D)\n",
    "    X_train_3d = data['X_train']\n",
    "    X_test_3d = data['X_test']\n",
    "    \n",
    "    y_train = data['y_train'].flatten()\n",
    "    y_true = data['y_test'].flatten()\n",
    "    \n",
    "    N_tr, L, D = X_train_3d.shape\n",
    "    \n",
    "    # 2. 模型构建与拟合\n",
    "    inputs = Input(shape=(L, D))\n",
    "    \n",
    "    # 【消融点】：移除模块 A (多尺度 1D 卷积/TimesNet表示)，特征直接送入 GRU 层\n",
    "    \n",
    "    # 模块 B: GRU 层 (降低隐藏单元数防过拟合，保留时间步)\n",
    "    x_gru = GRU(24, return_sequences=True)(inputs)\n",
    "    x_gru = Dropout(0.1)(x_gru)\n",
    "    \n",
    "    # 模块 C: MHA 层 (优化注意力头数与维度，引入残差与层归一化)\n",
    "    attn_out = MultiHeadAttention(num_heads=5, key_dim=16, dropout=0.1)(x_gru, x_gru)\n",
    "    x = LayerNormalization()(x_gru + attn_out)\n",
    "    \n",
    "    # 预测头 (使用全局平均池化替代 Flatten 减少参数量，降低过拟合风险)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(1, kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # 模块 D: 训练策略优化 (动态学习率 + 提前停止)\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
    "    ]\n",
    "    \n",
    "    # 使用 validation_split=0.1 监控过拟合，提高 epochs 让 ES 自动截断\n",
    "    model.fit(X_train_3d, y_train, epochs=150, batch_size=32, \n",
    "              validation_split=0.1, verbose=0, shuffle=False, callbacks=callbacks)\n",
    "    \n",
    "    # 3. 模型预测\n",
    "    y_pred = model.predict(X_test_3d, verbose=0).flatten()\n",
    "    \n",
    "    # 4. 基准预测 (零收益)\n",
    "    y_pred_baseline = np.zeros_like(y_true)\n",
    "    \n",
    "    # 5. 指标计算\n",
    "    rmse = np.sqrt(np.mean((y_true - y_pred)**2))\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    r2_os = 1 - (np.sum((y_true - y_pred)**2) / np.sum((y_true - y_pred_baseline)**2))\n",
    "    da = np.mean(np.sign(y_true) == np.sign(y_pred)) * 100\n",
    "    \n",
    "    # 6. 误差序列计算\n",
    "    e_t = y_true - y_pred\n",
    "    e0_t = y_true - y_pred_baseline\n",
    "    \n",
    "    # 7. 组装结果字典\n",
    "    results_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mae,\n",
    "        \"R2_OS\": r2_os,\n",
    "        \"DA\": da\n",
    "    }\n",
    "    \n",
    "    error_dict = {\n",
    "        \"model\": model_name,\n",
    "        \"window\": w,\n",
    "        \"errors\": e_t,\n",
    "        \"benchmark_errors\": e0_t\n",
    "    }\n",
    "    \n",
    "    # 8. 存储结果\n",
    "    all_results.append(results_dict)\n",
    "    all_errors.append(error_dict)\n",
    "    current_results[w] = results_dict\n",
    "\n",
    "# ---------------- 输出格式模拟 ----------------\n",
    "print(\"-\" * 110)\n",
    "# 表头第一行：窗口\n",
    "header_win = f\"{'Model':<20}\"\n",
    "# 表头第二行：指标\n",
    "header_met = f\"{'':<20}\"\n",
    "# 数据行\n",
    "row_data = f\"{model_name:<20}\"\n",
    "\n",
    "for w in experiment_data_refined.keys():\n",
    "    header_win += f\"{f'Window = {w}':^30}\"\n",
    "    header_met += f\"{'RMSE':>7} {'MAE':>7} {'R2_OS':>7} {'DA (%)':>7}  \"\n",
    "    \n",
    "    res = current_results[w]\n",
    "    row_data += f\"{res['RMSE']:>7.4f} {res['MAE']:>7.4f} {res['R2_OS']:>7.4f} {res['DA']:>7.2f}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 110)\n",
    "print(row_data)\n",
    "print(\"-\" * 110)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9485c760",
   "metadata": {},
   "source": [
    "### 消融DM检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "56aa285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. 定义基于滚动窗口的 Diebold-Mariano (DM) 检验函数 (带 HLN 校正)\n",
    "def dm_test(e1, e2, h=1, loss_type='MSE'):\n",
    "    \"\"\"\n",
    "    e1: 目标模型误差 (Target Model: TimesNet-GRU-MHA)\n",
    "    e2: 消融/基准模型误差 (Ablated/Baseline Model)\n",
    "    h: 预测步长 (Forecast horizon，此处默认为单步 1)\n",
    "    loss_type: 'MSE' 或 'MAE'\n",
    "    \"\"\"\n",
    "    # [安全机制]：强制尾部对齐，防止不同模型测试集截断长度差异导致 broadcast 报错\n",
    "    min_len = min(len(e1), len(e2))\n",
    "    e1 = np.array(e1)[-min_len:]\n",
    "    e2 = np.array(e2)[-min_len:]\n",
    "    \n",
    "    # 计算损失差异序列 d_t = Loss(e2) - Loss(e1)\n",
    "    # 注意：d_t > 0 说明基准模型(e2)误差更大，目标模型(e1)预测更准\n",
    "    if loss_type == 'MSE':\n",
    "        d = e2**2 - e1**2\n",
    "    elif loss_type == 'MAE':\n",
    "        d = np.abs(e2) - np.abs(e1)\n",
    "    else:\n",
    "        raise ValueError(\"loss_type 必须是 'MSE' 或 'MAE'\")\n",
    "        \n",
    "    T = len(d)\n",
    "    mean_d = np.mean(d)\n",
    "    \n",
    "    # 计算自协方差 (Auto-covariance)\n",
    "    def autocovariance(k):\n",
    "        if k == 0:\n",
    "            return np.mean((d - mean_d)**2)\n",
    "        else:\n",
    "            return np.sum((d[k:] - mean_d) * (d[:-k] - mean_d)) / T\n",
    "    \n",
    "    gamma_0 = autocovariance(0)\n",
    "    \n",
    "    # 对于多步预测 (h > 1)，计算 HAC 方差\n",
    "    var_d = gamma_0\n",
    "    for k in range(1, h):\n",
    "        var_d += 2 * autocovariance(k)\n",
    "        \n",
    "    if var_d == 0 or np.isnan(var_d):\n",
    "        return np.nan, np.nan\n",
    "        \n",
    "    # 计算基础 DM 统计量\n",
    "    dm_stat = mean_d / np.sqrt(var_d / T)\n",
    "    \n",
    "    # 加入 HLN 小样本偏差校正 (针对金融序列高噪和样本限制优化)\n",
    "    hln_correction = np.sqrt((T + 1 - 2*h + h*(h-1)/T) / T)\n",
    "    \n",
    "    # 将校正系数正确应用到统计量\n",
    "    dm_stat_hln = dm_stat * hln_correction\n",
    "    \n",
    "    # 使用自由度为 T-1 的 Student-t 分布计算双侧 p-value\n",
    "    p_value = 2 * (1 - stats.t.cdf(np.abs(dm_stat_hln), df=T-1))\n",
    "    \n",
    "    return dm_stat_hln, p_value\n",
    "\n",
    "# 判断显著性星号：只有当统计量 > 0 (即目标模型误差真的比对照组小) 且 p值显著时，才打星号\n",
    "def get_significance_stars(p, stat):\n",
    "    if np.isnan(p) or stat <= 0: return \"\"\n",
    "    if p < 0.01: return \"***\"\n",
    "    if p < 0.05: return \"**\"\n",
    "    if p < 0.10: return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "# 2. 提取需要检验的模型名称与动态获取窗口\n",
    "target_model = \"TimesNet-GRU-MHA\"\n",
    "\n",
    "# 动态获取所有对比模型 (直接从数据里抓取，不用手写)\n",
    "ablations = [\n",
    "    \"TimesNet-GRU-MHA (w/o FFT)\", \n",
    "    \"TimesNet-GRU-MHA (w/o 2D Inception)\", \n",
    "    \"TimesNet-MHA (w/o GRU)\", \n",
    "    \"TimesNet-GRU (w/o MHA)\",\n",
    "    \"GRU-MHA (w/o TimesNet)\"\n",
    "]\n",
    "\n",
    "# 从全局字典中动态获取所有存在的窗口\n",
    "windows = sorted(list(set([err['window'] for err in all_errors])))\n",
    "\n",
    "dm_results = {a: {} for a in ablations}\n",
    "\n",
    "# 3. 遍历计算目标模型与各个消融模型在不同窗口下的 DM 统计量\n",
    "for w in windows:\n",
    "    # 获取目标模型在当前窗口的误差序列\n",
    "    e_target_list = [err['errors'] for err in all_errors if err['model'] == target_model and err['window'] == w]\n",
    "    if not e_target_list:\n",
    "        print(f\"警告: 未找到目标模型 {target_model} 在 Window={w} 的误差序列。\")\n",
    "        continue\n",
    "    e_target = e_target_list[-1] \n",
    "    \n",
    "    for b in ablations:\n",
    "        e_base_list = [err['errors'] for err in all_errors if err['model'] == b and err['window'] == w]\n",
    "        if not e_base_list:\n",
    "            dm_results[b][w] = (np.nan, np.nan)\n",
    "            continue\n",
    "        e_base = e_base_list[-1]\n",
    "        \n",
    "        # 调用基于滚动窗口的 DM 检验\n",
    "        stat, p = dm_test(e_target, e_base, h=1, loss_type='MSE')\n",
    "        dm_results[b][w] = (stat, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "586d7d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Ablated/Baseline Model                             Window = 5                     Window = 21                     Window = 63           \n",
      "                                           DM-Stat    p-value      Sig     DM-Stat    p-value      Sig     DM-Stat    p-value      Sig  \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "TimesNet-GRU-MHA (w/o FFT)                2.465768   0.013851       **    5.422635   0.000000      ***   22.765255   0.000000      ***  \n",
      "TimesNet-GRU-MHA (w/o 2D Inception)       4.916009   0.000001      ***    2.418999   0.015757       **    4.317074   0.000018      ***  \n",
      "TimesNet-MHA (w/o GRU)                    2.845392   0.004533      ***   18.476673   0.000000      ***   11.130482   0.000000      ***  \n",
      "TimesNet-GRU (w/o MHA)                    4.051851   0.000055      ***    2.889436   0.003950      ***    3.406131   0.000689      ***  \n",
      "GRU-MHA (w/o TimesNet)                    4.537844   0.000006      ***    7.066214   0.000000      ***   16.629391   0.000000      ***  \n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Note: Target Model = TimesNet-GRU-MHA.\n",
      "DM-Stat represents the Diebold-Mariano test statistic with Harvey-Leybourne-Newbold (HLN) correction.\n",
      "A POSITIVE DM-Stat indicates that the Target Model has a SMALLER loss than the compared model.\n",
      "Significance levels: *** p<0.01, ** p<0.05, * p<0.1 (Only assigned when the Target Model is strictly better).\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 4. 输出格式模拟 (Rolling-Window DM Test Results) ----------------\n",
    "print(\"-\" * 135)\n",
    "header_win = f\"{'Ablated/Baseline Model':<40}\"\n",
    "header_met = f\"{'':<40}\"\n",
    "\n",
    "for w in windows:\n",
    "    header_win += f\"{f'Window = {w}':^32}\"\n",
    "    header_met += f\"{'DM-Stat':>10} {'p-value':>10} {'Sig':>8}  \"\n",
    "\n",
    "print(header_win)\n",
    "print(header_met)\n",
    "print(\"-\" * 135)\n",
    "\n",
    "for b in ablations:\n",
    "    row = f\"{b:<40}\"\n",
    "    for w in windows:\n",
    "        if w in dm_results[b] and not np.isnan(dm_results[b][w][0]):\n",
    "            stat, p = dm_results[b][w]\n",
    "            stars = get_significance_stars(p, stat)\n",
    "            row += f\"{stat:>10.6f} {p:>10.6f} {stars:>8}  \"\n",
    "        else:\n",
    "            row += f\"{'-':>15} {'-':>15} {'':>8}  \"\n",
    "    print(row)\n",
    "print(\"-\" * 135)\n",
    "print(f\"Note: Target Model = {target_model}.\")\n",
    "print(\"DM-Stat represents the Diebold-Mariano test statistic with Harvey-Leybourne-Newbold (HLN) correction.\")\n",
    "print(\"A POSITIVE DM-Stat indicates that the Target Model has a SMALLER loss than the compared model.\")\n",
    "print(\"Significance levels: *** p<0.01, ** p<0.05, * p<0.1 (Only assigned when the Target Model is strictly better).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29095f",
   "metadata": {},
   "source": [
    "消融实验 (Ablations) 导出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f55495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 提取并扁平化嵌套字典数据\n",
    "rows = []\n",
    "for model_name, window_data in dm_results.items():\n",
    "    for w, (stat, p) in window_data.items():\n",
    "        stars = get_significance_stars(p, stat) if not np.isnan(stat) else \"\"\n",
    "        rows.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Window\": w,\n",
    "            \"DM_Stat\": stat,\n",
    "            \"P_Value\": p,\n",
    "            \"Significance\": stars\n",
    "        })\n",
    "\n",
    "df_dm = pd.DataFrame(rows)\n",
    "\n",
    "# 直接建目录并保存 CSV\n",
    "os.makedirs('../results/tables', exist_ok=True)\n",
    "save_path = '../results/tables/dm_results_ablations.csv'\n",
    "df_dm.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"The DM results of Ablations have been saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975837a",
   "metadata": {},
   "source": [
    "### w/o Technical Indicators (仅使用原始价格)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffbe7d7",
   "metadata": {},
   "source": [
    "### w/o PiT Correction (使用前视偏差数据)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c2a64",
   "metadata": {},
   "source": [
    "## 保存实验结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ed9b7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# ----------------- 1. 导出模型评价指标 (all_results) -----------------\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv('../results/tables/model_evaluation_metrics.csv', index=False)\n",
    "\n",
    "# ----------------- 2. 导出预测误差序列 (all_errors) -----------------\n",
    "errors_pkl_path = '../results/tests/model_prediction_errors.pkl'\n",
    "with open(errors_pkl_path, 'wb') as f:\n",
    "    pickle.dump(all_errors, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
